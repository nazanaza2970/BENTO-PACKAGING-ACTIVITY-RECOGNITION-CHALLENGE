{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import glob\r\n",
    "from datetime import datetime\r\n",
    "import os\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from scipy import stats, signal\r\n",
    "from scipy.stats import mode\r\n",
    "from scipy.fft import fft\r\n",
    "from tsmoothie.smoother import LowessSmoother\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC, ExtraTreesClassifier as ETC\r\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "\r\n",
    "from bayes_opt import BayesianOptimization\r\n",
    "from skopt  import BayesSearchCV \r\n",
    "\r\n",
    "\r\n",
    "import lightgbm as lgb\r\n",
    "import xgboost as xgb\r\n",
    "\r\n",
    "from tqdm import tqdm, trange"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generic functions (usable for all test cases)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Core functions (Change path here)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def segmentation(df, overlap_rate, time_window):\r\n",
    "    seg_data = []\r\n",
    "    #convert overlap rate to step for sliding window\r\n",
    "    overlap = int((1 - overlap_rate)*time_window)\r\n",
    "    # interpolate\r\n",
    "    df = df.interpolate().ffill().fillna(0)\r\n",
    "    for i in range(0, len(df)-time_window+1, overlap):\r\n",
    "        seg_data.append(df.loc[i:i+time_window-1, :].copy().reset_index(drop=True))\r\n",
    "    return seg_data\r\n",
    "\r\n",
    "\r\n",
    "def rename_columns(df):\r\n",
    "    df.columns = [\r\n",
    "        \"FH_X\", \"FH_Y\", \"FH_Z\",     #1\r\n",
    "        \"TH_X\", \"TH_Y\", \"TH_Z\",     #2\r\n",
    "        \"RH_X\", \"RH_Y\", \"RH_Z\",     #3\r\n",
    "        \"RS_X\", \"RS_Y\", \"RS_Z\",     #4\r\n",
    "        \"RO_X\", \"RO_Y\", \"RO_Z\",     #5\r\n",
    "        \"RE_X\", \"RE_Y\", \"RE_Z\",     #6\r\n",
    "        \"RW_X\", \"RW_Y\", \"RW_Z\",     #7\r\n",
    "        \"LS_X\", \"LS_Y\", \"LS_Z\",     #8\r\n",
    "        \"LE_X\", \"LE_Y\", \"LE_Z\",     #9\r\n",
    "        \"LW_X\", \"LW_Y\", \"LW_Z\",     #10\r\n",
    "        \"RA_X\", \"RA_Y\", \"RA_Z\",     #11\r\n",
    "        \"LA_X\", \"LA_Y\", \"LA_Z\",     #12\r\n",
    "        \"VS_X\", \"VS_Y\", \"VS_Z\",     #13\r\n",
    "        \"subject_id\", \"activity\",   # Other columns\r\n",
    "    ]\r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "def dataloader(overlap, window_size, verbose=True):\r\n",
    "    if verbose:\r\n",
    "        print(\"loading the data...\", end=\"\\t\")\r\n",
    "    data_list = []\r\n",
    "    file_lengths = {1: [], 2: [], 3: []}\r\n",
    "    ##### CHANGE PATH ######\r\n",
    "    files = tqdm(glob.glob(\"../TrainData/*/*/*.csv\")) if verbose else glob.glob(\"../TrainData/*/*/*.csv\")\r\n",
    "    ##### ##### ##### ######\r\n",
    "    for file in files:\r\n",
    "        tempdf = pd.read_csv(file)\r\n",
    "        tempdf = rename_columns(tempdf)\r\n",
    "        segmented_data = segmentation(tempdf, overlap, window_size)\r\n",
    "        if len(segmented_data)>0:\r\n",
    "            person = segmented_data[0].reset_index(drop=True).loc[0, \"subject_id\"]\r\n",
    "            file_lengths[person].append(len(segmented_data))   \r\n",
    "        data_list.extend(segmented_data)\r\n",
    "    return data_list, file_lengths\r\n",
    "\r\n",
    "\r\n",
    "def feature_extractor(data_list, verbose=True):\r\n",
    "    if verbose:\r\n",
    "        print(f\"extracting the features...\", end=\"  \")\r\n",
    "    X, y = {1:[], 2:[], 3:[]}, {1:[], 2:[], 3:[]}\r\n",
    "    num_range = trange(0,len(data_list)) if verbose else range(0,len(data_list))\r\n",
    "    for j in num_range:\r\n",
    "        #extract only xyz columns\r\n",
    "        person = data_list[j].loc[0, \"subject_id\"]\r\n",
    "        x_data = data_list[j].drop(columns=[\"subject_id\",\"activity\"])\r\n",
    "        X[person].append(get_features(x_data))\r\n",
    "        y[person].append(data_list[j].reset_index(drop=True).loc[0, \"activity\"])\r\n",
    "    return X, y\r\n",
    "\r\n",
    "\r\n",
    "def majority_voting(predictions, file_lengths):\r\n",
    "    filtered_predictions = []\r\n",
    "    index = 0\r\n",
    "    for length in file_lengths:\r\n",
    "        file_pred = predictions[index:index+length]\r\n",
    "        modes = mode(file_pred)\r\n",
    "        majority_choice = modes.mode[0]\r\n",
    "        filtered_predictions.extend([majority_choice]*length)\r\n",
    "        index += length\r\n",
    "    return filtered_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_processed_dataset(overlap_rate, window_size, verbose=True):\r\n",
    "    data_list, file_lengths = dataloader(overlap_rate, window_size, verbose=verbose)\r\n",
    "    stream_list = []\r\n",
    "    for df in data_list:\r\n",
    "        stream_list.append(get_streams(df))\r\n",
    "    X, y = feature_extractor(stream_list, verbose=verbose)\r\n",
    "    return X, y, file_lengths\r\n",
    "\r\n",
    "\r\n",
    "def model_evaluator(model, X, y, file_lengths, n_repeats=10, voting=True, verbose=True):\r\n",
    "    scores = []\r\n",
    "    num_range = trange(n_repeats) if verbose else range(n_repeats)\r\n",
    "    for _ in num_range:\r\n",
    "        for p1, p2, p3 in [(1,2,3), (2,3,1), (3,1,2)]:\r\n",
    "            X_test, y_test = X[p1], y[p1]\r\n",
    "            X_train = X[p2] + X[p3]\r\n",
    "            y_train = y[p2] + y[p3]\r\n",
    "            # print(f\"training model for person {p1}/3...\", end=\"\\t\")\r\n",
    "            model.fit(X_train, y_train)\r\n",
    "            pred = model.predict(X_test)\r\n",
    "            if voting:\r\n",
    "                filtered_pred = majority_voting(pred, file_lengths[p1])\r\n",
    "                scores.append(accuracy_score(y_test, filtered_pred))\r\n",
    "            else:\r\n",
    "                scores.append(accuracy_score(y_test, pred))\r\n",
    "    if verbose:\r\n",
    "        print(f\"Mean Score: {np.mean(scores)}\")\r\n",
    "        print(f\"Std Score: {np.std(scores)}\")\r\n",
    "        print(f\"Min Score: {np.min(scores)}\")\r\n",
    "        print(f\"Max Score: {np.max(scores)}\")\r\n",
    "    return scores\r\n",
    "\r\n",
    "\r\n",
    "def scaled_model_evaluator(model, X, y, file_lengths, n_repeats=10, voting=True, verbose=True):\r\n",
    "    scores = []\r\n",
    "    num_range = trange(n_repeats) if verbose else range(n_repeats)\r\n",
    "    for _ in num_range:\r\n",
    "        for p1, p2, p3 in [(1,2,3), (2,3,1), (3,1,2)]:\r\n",
    "            X_test, y_test = X[p1], y[p1]\r\n",
    "            X_train = X[p2] + X[p3]\r\n",
    "            y_train = y[p2] + y[p3]\r\n",
    "            scaler = MinMaxScaler()\r\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\r\n",
    "            X_test_scaled = scaler.fit_transform(X_test)\r\n",
    "            # print(f\"training model for person {p1}/3...\", end=\"\\t\")\r\n",
    "            model.fit(X_train_scaled, y_train)\r\n",
    "            pred = model.predict(X_test_scaled)\r\n",
    "            if voting:\r\n",
    "                filtered_pred = majority_voting(pred, file_lengths[p1])\r\n",
    "                scores.append(accuracy_score(y_test, filtered_pred))\r\n",
    "            else:\r\n",
    "                scores.append(accuracy_score(y_test, pred))\r\n",
    "    if verbose:\r\n",
    "        print(f\"Mean Score: {np.mean(scores)}\")\r\n",
    "        print(f\"Std Score: {np.std(scores)}\")\r\n",
    "        print(f\"Min Score: {np.min(scores)}\")\r\n",
    "        print(f\"Max Score: {np.max(scores)}\")\r\n",
    "    return scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def bayesian_optimization(function, parameters):\r\n",
    "   n_iterations = 5\r\n",
    "   gp_params = {\"alpha\": 1e-4}\r\n",
    "\r\n",
    "   BO = BayesianOptimization(function, parameters)\r\n",
    "   BO.maximize(n_iter=n_iterations, **gp_params)\r\n",
    "\r\n",
    "   return BO.max"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stream Extractors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_speed_acc(x_data):\r\n",
    "    x_data = x_data.drop(columns=[\"activity\", \"subject_id\"])\r\n",
    "    speed = x_data.diff().fillna(0)\r\n",
    "    acc = speed.diff().fillna(0)\r\n",
    "    speed.columns = [f\"{col}_speed\" for col in speed.columns]\r\n",
    "    acc.columns = [f\"{col}_acc\" for col in acc.columns]\r\n",
    "    return speed, acc\r\n",
    "\r\n",
    "def get_speed_acc_jerk(x_data):\r\n",
    "    x_data = x_data.drop(columns=[\"activity\", \"subject_id\"])\r\n",
    "    speed = x_data.diff().fillna(0)\r\n",
    "    acc = speed.diff().fillna(0)\r\n",
    "    jerk = acc.diff().fillna(0)\r\n",
    "    speed.columns = [f\"{col}_speed\" for col in speed.columns]\r\n",
    "    acc.columns = [f\"{col}_acc\" for col in acc.columns]\r\n",
    "    jerk.columns = [f\"{col}_jerk\" for col in acc.columns]\r\n",
    "    return speed, acc, jerk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def joint_distance(x_data, joint1, joint2):\r\n",
    "    \"\"\"\r\n",
    "    returns the distance between two joints. \r\n",
    "    \"\"\"\r\n",
    "    x1, y1, z1 = x_data[f\"{joint1}_X\"], x_data[f\"{joint1}_Y\"], x_data[f\"{joint1}_Z\"]\r\n",
    "    x2, y2, z2 = x_data[f\"{joint2}_X\"], x_data[f\"{joint2}_Y\"], x_data[f\"{joint2}_Z\"]\r\n",
    "    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2 + (z2-z1)**2)\r\n",
    "    return distance\r\n",
    "\r\n",
    "def get_all_joint_distances(x_data):\r\n",
    "    \"\"\"\r\n",
    "    calculates all the necessary joint distances from the `x_data`, \r\n",
    "    adds columns to it and returns the modified `x_data`.\r\n",
    "    the two joints should not be essentially consecutive, \r\n",
    "    because the distance between two consecutive joints is always constant.\r\n",
    "    For example, distance between left_wrist and left_elbow is always constant.\r\n",
    "    \"\"\"\r\n",
    "    # joints\r\n",
    "    # Front head        ->  left shoulder       (1->8)\r\n",
    "    x_data[\"dist_FH_LS\"] = joint_distance(x_data, \"FH\", \"LS\")\r\n",
    "    # Front head        ->  right shoulder      (1->4)\r\n",
    "    x_data[\"dist_FH_RS\"] = joint_distance(x_data, \"FH\", \"RS\")\r\n",
    "    # left shoulder     ->  left wrist          (8->10)\r\n",
    "    x_data[\"dist_LS_LW\"] = joint_distance(x_data, \"LS\", \"LW\")\r\n",
    "    # right shoulder    ->  right wrist         (4->7)\r\n",
    "    x_data[\"dist_RS_RW\"] = joint_distance(x_data, \"RS\", \"RW\")\r\n",
    "    # v sacral          ->  left elbow          (13->9)\r\n",
    "    x_data[\"dist_VS_LE\"] = joint_distance(x_data, \"VS\", \"LE\")\r\n",
    "    # v sacral          ->  right elbow         (13->6)\r\n",
    "    x_data[\"dist_VS_RE\"] = joint_distance(x_data, \"VS\", \"RE\")\r\n",
    "    # v sacral          ->  left wrist          (13->10)\r\n",
    "    x_data[\"dist_VS_LW\"] = joint_distance(x_data, \"VS\", \"LW\")\r\n",
    "    # v sacral          ->  right wrist         (13->7)\r\n",
    "    x_data[\"dist_VS_RW\"] = joint_distance(x_data, \"VS\", \"RW\")\r\n",
    "    # v sacral          ->  rear head           (13->3)\r\n",
    "    x_data[\"dist_VS_RH\"] = joint_distance(x_data, \"VS\", \"RH\")\r\n",
    "    # v sacral          ->  top head            (13->2)\r\n",
    "    x_data[\"dist_VS_TH\"] = joint_distance(x_data, \"VS\", \"TH\")\r\n",
    "    # left wrist        ->  right wrist         (10->7)\r\n",
    "    x_data[\"dist_LW_RW\"] = joint_distance(x_data, \"LW\", \"RW\")\r\n",
    "    # left asis         ->  left wrist          (12->10)\r\n",
    "    x_data[\"dist_LA_LW\"] = joint_distance(x_data, \"LA\", \"LW\")\r\n",
    "    # right asis        ->  right wrist         (11->7)\r\n",
    "    x_data[\"dist_RA_RW\"] = joint_distance(x_data, \"RA\", \"RW\")\r\n",
    "    # left wrist        ->  top head            (10->2)\r\n",
    "    x_data[\"dist_LW_TH\"] = joint_distance(x_data, \"LW\", \"TH\")\r\n",
    "    # right wrist       ->  top head            (7->2)\r\n",
    "    x_data[\"dist_RW_TH\"] = joint_distance(x_data, \"RW\", \"TH\")\r\n",
    "    # top head          ->  left asis           (2->12)\r\n",
    "    x_data[\"dist_TH_LA\"] = joint_distance(x_data, \"TH\", \"LA\")\r\n",
    "    return x_data\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_all_joint_distances_red(x_data):\r\n",
    "    x_data[\"dist_FH_LS\"] = joint_distance(x_data, \"FH\", \"LS\")\r\n",
    "    # Front head        ->  right shoulder      (1->4)\r\n",
    "    x_data[\"dist_FH_RS\"] = joint_distance(x_data, \"FH\", \"RS\")\r\n",
    "    # left shoulder     ->  left wrist          (8->10)\r\n",
    "    x_data[\"dist_LS_LW\"] = joint_distance(x_data, \"LS\", \"LW\")\r\n",
    "    # right shoulder    ->  right wrist         (4->7)\r\n",
    "    x_data[\"dist_RS_RW\"] = joint_distance(x_data, \"RS\", \"RW\")\r\n",
    "    # v sacral          ->  left elbow          (13->9)\r\n",
    "    x_data[\"dist_VS_LE\"] = joint_distance(x_data, \"VS\", \"LE\")\r\n",
    "    # v sacral          ->  right elbow         (13->6)\r\n",
    "    x_data[\"dist_VS_RE\"] = joint_distance(x_data, \"VS\", \"RE\")\r\n",
    "    # v sacral          ->  left wrist          (13->10)\r\n",
    "    x_data[\"dist_VS_LW\"] = joint_distance(x_data, \"VS\", \"LW\")\r\n",
    "    # v sacral          ->  right wrist         (13->7)\r\n",
    "    x_data[\"dist_VS_RW\"] = joint_distance(x_data, \"VS\", \"RW\")\r\n",
    "    # v sacral          ->  rear head           (13->3)\r\n",
    "    # x_data[\"dist_VS_RH\"] = joint_distance(x_data, \"VS\", \"RH\")\r\n",
    "    # v sacral          ->  top head            (13->2)\r\n",
    "    # x_data[\"dist_VS_TH\"] = joint_distance(x_data, \"VS\", \"TH\")\r\n",
    "    # left wrist        ->  right wrist         (10->7)\r\n",
    "    x_data[\"dist_LW_RW\"] = joint_distance(x_data, \"LW\", \"RW\")\r\n",
    "    # left asis         ->  left wrist          (12->10)\r\n",
    "    x_data[\"dist_LA_LW\"] = joint_distance(x_data, \"LA\", \"LW\")\r\n",
    "    # right asis        ->  right wrist         (11->7)\r\n",
    "    x_data[\"dist_RA_RW\"] = joint_distance(x_data, \"RA\", \"RW\")\r\n",
    "    # left wrist        ->  top head            (10->2)\r\n",
    "    # x_data[\"dist_LW_TH\"] = joint_distance(x_data, \"LW\", \"TH\")\r\n",
    "    # # right wrist       ->  top head            (7->2)\r\n",
    "    # x_data[\"dist_RW_TH\"] = joint_distance(x_data, \"RW\", \"TH\")\r\n",
    "    # top head          ->  left asis           (2->12)\r\n",
    "    # x_data[\"dist_TH_LA\"] = joint_distance(x_data, \"TH\", \"LA\")\r\n",
    "    return x_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_all_joint_distances_red_diff(x_data):\r\n",
    "    x_data[\"dist_FH_LS\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"FH\", \"LS\")), 0)).tolist()\r\n",
    "    x_data[\"dist_FH_RS\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"FH\", \"RS\")), 0)).tolist()\r\n",
    "    x_data[\"dist_LS_LW\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"LS\", \"LW\")), 0)).tolist()\r\n",
    "    x_data[\"dist_RS_RW\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"RS\", \"RW\")), 0)).tolist()\r\n",
    "    x_data[\"dist_VS_LE\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"VS\", \"LE\")), 0)).tolist()\r\n",
    "    x_data[\"dist_VS_RE\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"VS\", \"RE\")), 0)).tolist()\r\n",
    "    x_data[\"dist_VS_LW\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"VS\", \"LW\")), 0)).tolist()\r\n",
    "    x_data[\"dist_VS_RW\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"VS\", \"RW\")), 0)).tolist()\r\n",
    "    x_data[\"dist_LW_RW\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"LW\", \"RW\")), 0)).tolist()\r\n",
    "    x_data[\"dist_LA_LW\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"LA\", \"LW\")), 0)).tolist()\r\n",
    "    x_data[\"dist_RA_RW\"] = np.nan_to_num(np.append(np.diff(joint_distance(x_data, \"RA\", \"RW\")), 0)).tolist()\r\n",
    "    return x_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def joint_angle(x_data, joint1, joint2, joint3):\r\n",
    "    x1, y1, z1 = x_data[f\"{joint1}_X\"], x_data[f\"{joint1}_Y\"], x_data[f\"{joint1}_Z\"]\r\n",
    "    x2, y2, z2 = x_data[f\"{joint2}_X\"], x_data[f\"{joint2}_Y\"], x_data[f\"{joint2}_Z\"]\r\n",
    "    x3, y3, z3 = x_data[f\"{joint3}_X\"], x_data[f\"{joint3}_Y\"], x_data[f\"{joint3}_Z\"]\r\n",
    "    v1 = np.array([x2-x1, y2-y1, z2-z1]).T\r\n",
    "    v2 = np.array([x3-x2, y3-y2, z3-z2]).T\r\n",
    "    v1_unit = v1/np.expand_dims(np.linalg.norm(v1, axis=1), axis=1)\r\n",
    "    v2_unit = v2/np.expand_dims(np.linalg.norm(v2, axis=1), axis=1)\r\n",
    "    angle = np.arccos(np.sum(v1_unit*v2_unit, axis=1)) # dot multiplication\r\n",
    "    return angle\r\n",
    "\r\n",
    "def get_all_joint_angles(x_data):\r\n",
    "    # joints\r\n",
    "    # left shoulder     ->  left elbow      ->  left wrist      (8->9->10)\r\n",
    "    x_data[\"angle_LS_LE_LW\"] = joint_angle(x_data, \"LS\", \"LE\", \"LW\")\r\n",
    "    # right shoulder    ->  right elbow     ->  right wrist     (4->6->7)\r\n",
    "    x_data[\"angle_RS_RE_RW\"] = joint_angle(x_data, \"RS\", \"RE\", \"RW\")\r\n",
    "    # right shoulder    ->  left shoulder   ->  front head      (4->8->1)\r\n",
    "    x_data[\"angle_RS_LS_FH\"] = joint_angle(x_data, \"RS\", \"LS\", \"FH\")\r\n",
    "    # right shoulder    ->  left shoulder   ->  left elbow      (4->8->9)\r\n",
    "    x_data[\"angle_RS_LS_LE\"] = joint_angle(x_data, \"RS\", \"LS\", \"LE\")\r\n",
    "    # left shoulder     ->  right shoulder  ->  right elbow     (8->4->6)\r\n",
    "    x_data[\"angle_LS_RS_RE\"] = joint_angle(x_data, \"LS\", \"RS\", \"RE\")\r\n",
    "    # v sacral          ->  right offset    ->  rear head       (13->5->3)\r\n",
    "    x_data[\"angle_VS_RO_RH\"] = joint_angle(x_data, \"VS\", \"RO\", \"RH\")\r\n",
    "    # vsacral           ->  top head        ->  front head      (13->2->1)\r\n",
    "    x_data[\"angle_VS_TH_FH\"] = joint_angle(x_data, \"VS\", \"TH\", \"FH\")\r\n",
    "    # v sacral          ->  left shoulder   ->  left elbow      (13->8->9)\r\n",
    "    x_data[\"angle_VS_LS_LE\"] = joint_angle(x_data, \"VS\", \"LS\", \"LE\")\r\n",
    "    # v sacral          ->  right shoulder  ->  right elbow     (13->4->6)\r\n",
    "    x_data[\"angle_VS_RS_RE\"] = joint_angle(x_data, \"VS\", \"RS\", \"RE\")\r\n",
    "    # left asis         ->  left shoulder   ->  left elbow      (12->8->9)\r\n",
    "    x_data[\"angle_LA_LS_LE\"] = joint_angle(x_data, \"LA\", \"LS\", \"LE\")\r\n",
    "    # right asis        -> right shoulder   ->  right elbow     (11->4->6)\r\n",
    "    x_data[\"angle_RA_RS_RE\"] = joint_angle(x_data, \"RA\", \"RS\", \"RE\")\r\n",
    "    return x_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def get_all_joint_angles_red(x_data):\r\n",
    "    # joints\r\n",
    "    x_data[\"angle_LS_LE_LW\"] = joint_angle(x_data, \"LS\", \"LE\", \"LW\")\r\n",
    "    x_data[\"angle_RS_RE_RW\"] = joint_angle(x_data, \"RS\", \"RE\", \"RW\")\r\n",
    "    x_data[\"angle_RS_LS_LE\"] = joint_angle(x_data, \"RS\", \"LS\", \"LE\")\r\n",
    "    x_data[\"angle_LS_RS_RE\"] = joint_angle(x_data, \"LS\", \"RS\", \"RE\")\r\n",
    "    x_data[\"angle_VS_RO_RH\"] = joint_angle(x_data, \"VS\", \"RO\", \"RH\")\r\n",
    "    return x_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def get_all_joint_angles_diff_red(x_data):\r\n",
    "    # joints\r\n",
    "    x_data[\"ang_dif_LS_LE_LW\"] = np.nan_to_num(np.append(np.diff(joint_angle(x_data, \"LS\", \"LE\", \"LW\")), 0)).tolist()\r\n",
    "    x_data[\"ang_dif_RS_RE_RW\"] = np.nan_to_num(np.append(np.diff(joint_angle(x_data, \"RS\", \"RE\", \"RW\")), 0)).tolist()\r\n",
    "    x_data[\"ang_dif_RS_LS_LE\"] = np.nan_to_num(np.append(np.diff(joint_angle(x_data, \"RS\", \"LS\", \"LE\")), 0)).tolist()\r\n",
    "    x_data[\"ang_dif_LS_RS_RE\"] = np.nan_to_num(np.append(np.diff(joint_angle(x_data, \"LS\", \"RS\", \"RE\")), 0)).tolist()\r\n",
    "    x_data[\"ang_dif_VS_RO_RH\"] = np.nan_to_num(np.append(np.diff(joint_angle(x_data, \"VS\", \"RO\", \"RH\")), 0)).tolist()\r\n",
    "    return x_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def plane_angles(x_data, joint1, joint2):\r\n",
    "    x1, y1, z1 = x_data[f\"{joint1}_X\"], x_data[f\"{joint1}_Y\"], x_data[f\"{joint1}_Z\"]\r\n",
    "    x2, y2, z2 = x_data[f\"{joint2}_X\"], x_data[f\"{joint2}_Y\"], x_data[f\"{joint2}_Z\"]\r\n",
    "    v = np.array([x2-x1, y2-y1, z2-z1]).T\r\n",
    "    vx = np.array([1, 0, 0])\r\n",
    "    vy = np.array([0, 1, 0])\r\n",
    "    vz = np.array([0, 0, 1])\r\n",
    "    v_unit = v/np.expand_dims(np.linalg.norm(v, axis=1), axis=1)\r\n",
    "    angle_x = np.arccos(np.sum(v_unit*vx, axis=1)) \r\n",
    "    angle_y = np.arccos(np.sum(v_unit*vy, axis=1)) \r\n",
    "    angle_z = np.arccos(np.sum(v_unit*vz, axis=1)) \r\n",
    "    return angle_x, angle_y, angle_z\r\n",
    "\r\n",
    "def get_all_angles_with_plane(x_data):\r\n",
    "    # joints\r\n",
    "    # arm angles: left shoulder     ->  left elbow \r\n",
    "    x_data[\"angle_x_LS_LE\"], x_data[\"angle_y_LS_LE\"], x_data[\"angle_z_LS_LE\"] = plane_angles(x_data, \"LS\", \"LE\")\r\n",
    "    # forearm angles: left elbow    ->  left  wrist\r\n",
    "    x_data[\"angle_x_LE_LW\"], x_data[\"angle_y_LE_LW\"], x_data[\"angle_z_LE_LW\"] = plane_angles(x_data, \"LE\", \"LW\")\r\n",
    "    # arm angles: right shoulder    ->  right elbow \r\n",
    "    x_data[\"angle_x_RS_RE\"], x_data[\"angle_y_RS_RE\"], x_data[\"angle_z_RS_RE\"] = plane_angles(x_data, \"RS\", \"RE\")\r\n",
    "    # forearm angles: right elbow   ->  right  wrist\r\n",
    "    x_data[\"angle_x_RE_RW\"], x_data[\"angle_y_RE_RW\"], x_data[\"angle_z_RE_RW\"] = plane_angles(x_data, \"RE\", \"RW\")\r\n",
    "    # backbone angles: v sacral     ->  rear head\r\n",
    "    # x_data[\"angle_x_VS_RH\"], x_data[\"angle_y_VS_RH\"], x_data[\"angle_z_VS_RH\"] = plane_angles(x_data, \"VS\", \"RH\")\r\n",
    "    return x_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def get_all_angles_with_plane_diff(x_data):\r\n",
    "    # joints\r\n",
    "    # arm angles: left shoulder     ->  left elbow \r\n",
    "    dif = lambda x: np.nan_to_num(np.append(np.diff(x), 0)).tolist()\r\n",
    "    a, b, c = plane_angles(x_data, \"LS\", \"LE\")\r\n",
    "    x_data[\"angle_x_LS_LE\"], x_data[\"angle_y_LS_LE\"], x_data[\"angle_z_LS_LE\"] = dif(a), dif(b), dif(c)\r\n",
    "    # forearm angles: left elbow    ->  left  wrist\r\n",
    "    a, b, c = plane_angles(x_data, \"LE\", \"LW\")\r\n",
    "    x_data[\"angle_x_LE_LW\"], x_data[\"angle_y_LE_LW\"], x_data[\"angle_z_LE_LW\"] =  dif(a), dif(b), dif(c)\r\n",
    "    # arm angles: right shoulder    ->  right elbow \r\n",
    "    a, b, c = plane_angles(x_data, \"RS\", \"RE\")\r\n",
    "    x_data[\"angle_x_RS_RE\"], x_data[\"angle_y_RS_RE\"], x_data[\"angle_z_RS_RE\"] =  dif(a), dif(b), dif(c)\r\n",
    "    # forearm angles: right elbow   ->  right  wrist\r\n",
    "    a, b, c = plane_angles(x_data, \"RE\", \"RW\")\r\n",
    "    x_data[\"angle_x_RE_RW\"], x_data[\"angle_y_RE_RW\"], x_data[\"angle_z_RE_RW\"] =  dif(a), dif(b), dif(c)\r\n",
    "    # backbone angles: v sacral     ->  rear head\r\n",
    "    # x_data[\"angle_x_VS_RH\"], x_data[\"angle_y_VS_RH\"], x_data[\"angle_z_VS_RH\"] = plane_angles(x_data, \"VS\", \"RH\")\r\n",
    "    return x_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processed functions (add/remove streams/features here)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def remove_acc():\r\n",
    "    def get_streams(x_data):\r\n",
    "        speed, acc = get_speed_acc(x_data)\r\n",
    "        x_data = pd.concat([x_data, speed], axis=1)\r\n",
    "        x_data = get_all_joint_distances(x_data)\r\n",
    "        return x_data\r\n",
    "\r\n",
    "    def get_features(x_data):\r\n",
    "        features = []\r\n",
    "        cols = x_data.columns.tolist()\r\n",
    "        for k in cols:\r\n",
    "            features.append(x_data[k].std(ddof=0))\r\n",
    "            features.append(np.max(x_data[k]))\r\n",
    "            features.append(np.min(x_data[k]))\r\n",
    "            features.append(np.median(x_data[k]))        \r\n",
    "        return features\r\n",
    "    joint_names = ['FH', 'TH', 'RH', 'RS', 'RO', 'RE', 'RW', 'LS', 'LE', 'LW', 'RA', 'LA', 'VS']\r\n",
    "    pos_cols = [i+j for i in joint_names for j in [\"_X\", \"_Y\", \"_Z\"]]\r\n",
    "    speed_cols = [f\"{col}_speed\" for col in pos_cols]\r\n",
    "    distance_cols = ['dist_FH_LS', 'dist_FH_RS', 'dist_LS_LW', 'dist_RS_RW', 'dist_VS_LE', 'dist_VS_RE', \r\n",
    "        'dist_VS_LW', 'dist_VS_RW','dist_VS_RH', 'dist_VS_TH', 'dist_LW_RW', 'dist_LA_LW', 'dist_RA_RW', \r\n",
    "        'dist_LW_TH', 'dist_RW_TH', 'dist_TH_LA']\r\n",
    "    colnames = pos_cols + speed_cols + distance_cols\r\n",
    "    return get_streams, get_features, colnames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def angle_dif_red_remove_acc():\r\n",
    "    def get_streams(x_data):\r\n",
    "        speed, acc = get_speed_acc(x_data)\r\n",
    "        x_data = pd.concat([x_data, speed], axis=1)\r\n",
    "        x_data = get_all_joint_distances(x_data)\r\n",
    "        x_data = get_all_joint_angles_diff_red(x_data)\r\n",
    "        return x_data\r\n",
    "\r\n",
    "    def get_features(x_data):\r\n",
    "        features = []\r\n",
    "        cols = x_data.columns.tolist()\r\n",
    "        for k in cols:\r\n",
    "            features.append(x_data[k].std(ddof=0))\r\n",
    "            features.append(np.max(x_data[k]))\r\n",
    "            features.append(np.min(x_data[k]))\r\n",
    "            features.append(np.median(x_data[k]))        \r\n",
    "        return features\r\n",
    "    joint_names = ['FH', 'TH', 'RH', 'RS', 'RO', 'RE', 'RW', 'LS', 'LE', 'LW', 'RA', 'LA', 'VS']\r\n",
    "    pos_cols = [i+j for i in joint_names for j in [\"_X\", \"_Y\", \"_Z\"]]\r\n",
    "    speed_cols = [f\"{col}_speed\" for col in pos_cols]\r\n",
    "    distance_cols = ['dist_FH_LS', 'dist_FH_RS', 'dist_LS_LW', 'dist_RS_RW', 'dist_VS_LE', 'dist_VS_RE', \r\n",
    "        'dist_VS_LW', 'dist_VS_RW','dist_VS_RH', 'dist_VS_TH', 'dist_LW_RW', 'dist_LA_LW', 'dist_RA_RW', \r\n",
    "        'dist_LW_TH', 'dist_RW_TH', 'dist_TH_LA']\r\n",
    "    angle_dif_cols = [\"LSLELW\", \"RSRERW\", \"RSLSLE\", \"LSRSRE\", \"VSRORH\"]\r\n",
    "    colnames = pos_cols + speed_cols + distance_cols + angle_dif_cols\r\n",
    "    return get_streams, get_features, colnames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def dist_red_angle_red_diff_remove_acc():\r\n",
    "    def get_streams(x_data):\r\n",
    "        speed, acc = get_speed_acc(x_data)\r\n",
    "        x_data = pd.concat([x_data, speed], axis=1)\r\n",
    "        x_data = get_all_joint_distances_red(x_data)\r\n",
    "        x_data = get_all_joint_angles_diff_red(x_data)\r\n",
    "        return x_data\r\n",
    "\r\n",
    "    def get_features(x_data):\r\n",
    "        features = []\r\n",
    "        cols = x_data.columns.tolist()\r\n",
    "        for k in cols:\r\n",
    "            features.append(x_data[k].std(ddof=0))\r\n",
    "            features.append(np.max(x_data[k]))\r\n",
    "            features.append(np.min(x_data[k]))\r\n",
    "            features.append(np.median(x_data[k]))        \r\n",
    "        return features\r\n",
    "    joint_names = ['FH', 'TH', 'RH', 'RS', 'RO', 'RE', 'RW', 'LS', 'LE', 'LW', 'RA', 'LA', 'VS']\r\n",
    "    pos_cols = [i+j for i in joint_names for j in [\"_X\", \"_Y\", \"_Z\"]]\r\n",
    "    speed_cols = [f\"{col}_speed\" for col in pos_cols]\r\n",
    "    distance_cols = ['dist_FH_LS', 'dist_FH_RS', 'dist_LS_LW', 'dist_RS_RW', 'dist_VS_LE', 'dist_VS_RE', \r\n",
    "        'dist_VS_LW', 'dist_VS_RW', 'dist_LW_RW', 'dist_LA_LW', 'dist_RA_RW']\r\n",
    "    angle_dif_cols = [\"LSLELW\", \"RSRERW\", \"RSLSLE\", \"LSRSRE\", \"VSRORH\"]\r\n",
    "    colnames = pos_cols + speed_cols + distance_cols + angle_dif_cols\r\n",
    "    return get_streams, get_features, colnames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def dist_red_angle_red_diff_plane_remove_acc():\r\n",
    "    def get_streams(x_data):\r\n",
    "        speed, acc = get_speed_acc(x_data)\r\n",
    "        x_data = pd.concat([x_data, speed], axis=1)\r\n",
    "        x_data = get_all_joint_distances_red(x_data)\r\n",
    "        x_data = get_all_joint_angles_diff_red(x_data)\r\n",
    "        x_data = get_all_angles_with_plane(x_data)\r\n",
    "        return x_data\r\n",
    "\r\n",
    "    def get_features(x_data):\r\n",
    "        features = []\r\n",
    "        cols = x_data.columns.tolist()\r\n",
    "        for k in cols:\r\n",
    "            features.append(x_data[k].std(ddof=0))\r\n",
    "            features.append(np.max(x_data[k]))\r\n",
    "            features.append(np.min(x_data[k]))\r\n",
    "            features.append(np.median(x_data[k]))        \r\n",
    "        return features\r\n",
    "    joint_names = ['FH', 'TH', 'RH', 'RS', 'RO', 'RE', 'RW', 'LS', 'LE', 'LW', 'RA', 'LA', 'VS']\r\n",
    "    pos_cols = [i+j for i in joint_names for j in [\"_X\", \"_Y\", \"_Z\"]]\r\n",
    "    speed_cols = [f\"{col}_speed\" for col in pos_cols]\r\n",
    "    distance_cols = ['dist_FH_LS', 'dist_FH_RS', 'dist_LS_LW', 'dist_RS_RW', 'dist_VS_LE', 'dist_VS_RE', \r\n",
    "        'dist_VS_LW', 'dist_VS_RW', 'dist_LW_RW', 'dist_LA_LW', 'dist_RA_RW']\r\n",
    "    angle_dif_cols = [\"LSLELW\", \"RSRERW\", \"RSLSLE\", \"LSRSRE\", \"VSRORH\"]\r\n",
    "    plane_cols = [\"xLSLE\", \"yLSLE\", \"zLSLE\", \"xLELW\", \"yLELW\", \"zLELW\", \"xRSRE\", \"yRSRE\", \"zRSRE\", \"xRERW\", \"yRERW\", \"zRERW\"]\r\n",
    "    colnames = pos_cols + speed_cols + distance_cols + angle_dif_cols + plane_cols\r\n",
    "    return get_streams, get_features, colnames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def dist_red_dist_red_diff_angle_red_diff_remove_acc():\r\n",
    "    def get_streams(x_data):\r\n",
    "        speed, acc = get_speed_acc(x_data)\r\n",
    "        x_data = pd.concat([x_data, speed], axis=1)\r\n",
    "        x_data = get_all_joint_distances_red(x_data)\r\n",
    "        x_data = get_all_joint_distances_red_diff(x_data)\r\n",
    "        x_data = get_all_joint_angles_diff_red(x_data)\r\n",
    "        return x_data\r\n",
    "\r\n",
    "    def get_features(x_data):\r\n",
    "        features = []\r\n",
    "        cols = x_data.columns.tolist()\r\n",
    "        for k in cols:\r\n",
    "            features.append(x_data[k].std(ddof=0))\r\n",
    "            features.append(np.max(x_data[k]))\r\n",
    "            features.append(np.min(x_data[k]))\r\n",
    "            features.append(np.median(x_data[k]))        \r\n",
    "        return features\r\n",
    "    joint_names = ['FH', 'TH', 'RH', 'RS', 'RO', 'RE', 'RW', 'LS', 'LE', 'LW', 'RA', 'LA', 'VS']\r\n",
    "    pos_cols = [i+j for i in joint_names for j in [\"_X\", \"_Y\", \"_Z\"]]\r\n",
    "    speed_cols = [f\"{col}_speed\" for col in pos_cols]\r\n",
    "    distance_cols = ['dist_FH_LS', 'dist_FH_RS', 'dist_LS_LW', 'dist_RS_RW', 'dist_VS_LE', 'dist_VS_RE', \r\n",
    "        'dist_VS_LW', 'dist_VS_RW', 'dist_LW_RW', 'dist_LA_LW', 'dist_RA_RW']\r\n",
    "    distance_diff_cols = [\"diff_\"+i for i in distance_cols]\r\n",
    "    angle_dif_cols = [\"LSLELW\", \"RSRERW\", \"RSLSLE\", \"LSRSRE\", \"VSRORH\"]\r\n",
    "    colnames = pos_cols + speed_cols + distance_cols + distance_diff_cols + angle_dif_cols\r\n",
    "    return get_streams, get_features, colnames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <p style=\"color:red\"> <b> bayes optimization: dist reduced + angle difference reduced + remove acceleration </b> </p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "get_streams, get_features, colnames = dist_red_angle_red_diff_remove_acc()\r\n",
    "overlap_rate, window_size = 0.8, 4000\r\n",
    "X, y, file_lengths = get_processed_dataset(overlap_rate, window_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading the data...\t"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 151/151 [00:13<00:00, 11.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "extracting the features...  "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 512/512 [00:30<00:00, 16.66it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "def eval_function(n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf):\r\n",
    "    model = RFC(\r\n",
    "                n_estimators=int(max(n_estimators,0)), \r\n",
    "                criterion=\"entropy\" if criterion>=0.5 else \"gini\",                                                             \r\n",
    "                max_depth=int(max(max_depth, 1)),\r\n",
    "                min_samples_split=int(max(min_samples_split,2)), \r\n",
    "                min_samples_leaf=int(min_samples_leaf),\r\n",
    "                n_jobs=-1)\r\n",
    "    scores = scaled_model_evaluator(model, X, y, file_lengths, n_repeats=5, voting=True, verbose=True)\r\n",
    "    return np.median(scores)\r\n",
    "\r\n",
    "# need to give the range in the tuples\r\n",
    "parameters = {\"n_estimators\": (1000, 5000),\r\n",
    "                \"max_depth\": (8, 60),\r\n",
    "                \"min_samples_split\": (2, 10),\r\n",
    "                \"criterion\": (0, 1),\r\n",
    "                \"min_samples_leaf\": (1,8)\r\n",
    "                }\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_solution = bayesian_optimization(eval_function, parameters) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "best_solution"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8097345132743363,\n",
       " 'params': {'criterion': 0.18041252076428138,\n",
       "  'max_depth': 48.10632563606063,\n",
       "  'min_samples_leaf': 5.693290179489262,\n",
       "  'min_samples_split': 2.21796460693196,\n",
       "  'n_estimators': 2332.4339379229414}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "model = RFC(2332, criterion=\"gini\", max_depth=48, min_samples_leaf=5, min_samples_split=2, n_jobs=-1)\r\n",
    "scores = scaled_model_evaluator(model, X, y, file_lengths, n_repeats=10, voting=True, verbose=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [02:49<00:00, 16.94s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Score: 0.8005794824269304\n",
      "Std Score: 0.015106236114833492\n",
      "Min Score: 0.7669172932330827\n",
      "Max Score: 0.827433628318584\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}